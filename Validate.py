from flask import Flask, request, jsonify
from transformers import AutoTokenizer, AutoModel
import torch
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

app = Flask(__name__)

# Load the MPNet model and tokenizer
model_path = "mpnet_model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModel.from_pretrained(model_path)

def get_embedding(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    # Use the mean pooling for sentence embeddings
    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()
    return embeddings

@app.route('/similarity', methods=['POST'])
def similarity():
    data = request.json
    text1 = data.get("text1")
    text2 = data.get("text2")

    if not text1 or not text2:
        return jsonify({"error": "Both text1 and text2 must be provided"}), 400

    embedding1 = get_embedding(text1)
    embedding2 = get_embedding(text2)

    # Calculate cosine similarity
    similarity_score = cosine_similarity([embedding1], [embedding2])[0][0]

    return jsonify({"similarity": similarity_score})

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
